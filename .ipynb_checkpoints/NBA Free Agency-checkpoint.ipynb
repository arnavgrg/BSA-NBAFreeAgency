{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Free Agency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to determine whether the top 10 NBA free agents (or players who opt for player option in their contracts) are likely stay or leave a team during free agency or the mid-season trade deadline. This will be determined using NLP techniques on phrases extracted from tweets, news, interviews, polls, basketball stats, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 NBA Free Agents 2019\n",
    "According to SBNation and ESPN these players are: <br>\n",
    "Link: https://www.sbnation.com/nba/2018/7/30/17616436/nba-free-agency-2019-list-kevin-durant-kyrie-irving\n",
    "\n",
    "1. Kevin Durant\n",
    "2. Kawhi Leonard\n",
    "3. Kyrie Irving\n",
    "4. Jimmy Butler \n",
    "5. Klay Thompson\n",
    "6. DeMarcus Cousins\n",
    "7. Al Horford\n",
    "8. Kemba Walker\n",
    "9. Khris Middleton\n",
    "10. Eric Bledsoe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup #Web Scraping\n",
    "import re #Regex\n",
    "from nltk.tokenize import TweetTokenizer #Tokenizer\n",
    "import requests #Web Scraping\n",
    "import urllib3 #Web Scraping\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Wikipedia Links from Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "links1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize into 'get' query formats \n",
    "query = 'Lebron James'\n",
    "query = urllib.parse.quote_plus(query)\n",
    "\n",
    "#Get request to a link; return status code 200 if successful. r.text has all the text saved\n",
    "r = requests.get('https://www.google.com/search?q=site:wikipedia.com+{}&gbv=1&sei=YwHNVpHLOYiWmQHk3K24Cw'.format(query))\n",
    "\n",
    "#Convert it to a soup object, but parsing it usin html so it understands the text being parsed. \n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "for item in soup.find_all('h3', attrs={'class' : 'r'}):\n",
    "    links1.append(item.a['href'][7:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Links from Google Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Lebron James Lakers\"\n",
    "google_search = \"https://www.google.com/search?sclient=psy-ab&client=ubuntu&hs=k5b&channel=fs&biw=1366&bih=648&noj=1&q=\" + query\n",
    "\n",
    "r = requests.get(google_search)\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "for item in soup.find_all('h3', attrs={'class' : 'r'}):\n",
    "    links.append(item.a['href'][7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the Links\n",
    "n = len(links)\n",
    "for i in range(0,n):\n",
    "    x = links[i].find('&') \n",
    "    if x != -1:\n",
    "        links[i] = links[i][:x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the links\n",
    "for i in range(0,n):\n",
    "    x = links[i].find('%')\n",
    "    if x != -1:\n",
    "        links[i] = links[i][:x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of misprint\n",
    "for i in links:\n",
    "    if i[0] == '?':\n",
    "        links.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.usatoday.com/story/sports/nba/2018/10/30/lebron-james-lakers-warning-timberwolves/1816624002/\n",
      "http://www.espn.com/nba/story/_/id/24854936/lebron-james-creates-first-highlights-lakers-preseason-debut\n",
      "https://www.reuters.com/article/us-basketball-nba-lal-lebron-james/inexperienced-lakers-starting-to-wear-on-lebron-idUSKCN1N424M\n",
      "https://www.youtube.com/watch\n",
      "http://www.latimes.com/la-sp-lebron-james-lakers-updates-htmlstory.html\n",
      "https://lakersstore.com/collections/welcome-lebron-james\n",
      "https://www.ocregister.com/tag/lebron-james/\n",
      "https://sports.yahoo.com/lebron-james-teases-lakers-fans-playing-together-kobe-bryant-imagine-213914553.html\n"
     ]
    }
   ],
   "source": [
    "#Displaying the links\n",
    "n = len(links)\n",
    "for i in range(0,n):\n",
    "    print(links[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing Everything on a page\n",
    "r = requests.get(links[1])\n",
    "\n",
    "soup1 = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "text = soup1.find_all('p')\n",
    "\n",
    "page_text = \"\"\n",
    "\n",
    "for item in text:\n",
    "    str_contents = str(item.contents)\n",
    "    len_contents = len(str_contents)\n",
    "    page_text += str_contents[1:len_contents-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
